---
title: Eu tentei ensinar uma IA a seguir regras. Ela tentou ser inteligente demais.
description: Uma histÃ³ria real sobre por que inteligÃªncia artificial falha em ambientes regulados â€” e como mudar o papel da IA muda tudo.
date: "2024-01-02"
authors:
  - repo
image: /images/blog/blog-post-3.png
---

## Tudo comeÃ§ou com uma pergunta simples

> *â€œDÃ¡ para usar inteligÃªncia artificial para classificar eventos regulatÃ³rios?â€*

Parecia Ã³bvio que sim.  
Afinal, a IA jÃ¡ escreve textos, interpreta documentos complexos, responde perguntas difÃ­ceisâ€¦  
por que nÃ£o ajudaria a classificar um incidente ambiental ou de seguranÃ§a?

Na prÃ¡tica, a resposta foi: **nÃ£o do jeito que eu imaginava**.

---

## A primeira tentativa: â€œdeixa a IA decidirâ€

Como muita gente faz hoje, comecei pelo caminho mais fÃ¡cil:

- envio o texto do evento,
- junto a norma aplicÃ¡vel,
- peÃ§o para a IA dizer qual Ã© a classificaÃ§Ã£o correta.

Funcionouâ€¦ mais ou menos.

Ã€s vezes ela acertava com uma clareza impressionante.  
Outras vezes, dava respostas que *soavam* inteligentes â€” mas estavam simplesmente erradas.

E o pior:  
eram erradas **com convicÃ§Ã£o**.

---

## Quando â€œparece certoâ€ nÃ£o Ã© suficiente

Em um dos testes, o evento dizia algo como:

> *â€œHouve um vazamento de Ã³leo diesel que atingiu um corpo hÃ­drico.â€*

Para qualquer pessoa da Ã¡rea, isso Ã© um acidente ambiental claro.

A IA respondeu algo como:

> *â€œTrata-se de um incidente operacional com potencial impacto ambiental.â€*

Tecnicamente bonito.  
Regulatoriamente errado.

A norma nÃ£o pergunta se *parece* incidente.  
Ela pergunta:

- houve vazamento?
- atingiu o meio ambiente?
- qual foi o volume?

NÃ£o existe interpretaÃ§Ã£o.  
Existe **regra**.

Foi aÃ­ que caiu a ficha.

---

## O erro nÃ£o era da IA. Era do papel que eu dei a ela.

A IA estava fazendo exatamente o que foi treinada para fazer:

- interpretar textos,
- inferir significados,
- escolher a resposta mais provÃ¡vel.

O problema Ã© que **regulaÃ§Ã£o nÃ£o funciona por probabilidade**.

Ela funciona como um checklist rÃ­gido:

> se X aconteceu, entÃ£o Y se aplica.

NÃ£o importa se parece exagero.  
NÃ£o importa se foi pequeno.  
NÃ£o importa se â€œna maioria dos casosâ€ seria outra coisa.

---

## Uma analogia que mudou tudo

Imagine um GPS que, em vez de seguir regras de trÃ¢nsito, resolvesse â€œinterpretar o contextoâ€:

> â€œEsse sinal vermelho parece opcional.â€  
> â€œNormalmente ninguÃ©m para aqui.â€  
> â€œA chance de acidente Ã© baixa.â€

Seria um desastre.

E eu estava tentando usar uma IA exatamente assim â€”  
como um GPS opinativo em um ambiente que exige **semÃ¡foros absolutos**.

---

## A virada: e se a IA nÃ£o decidisse nada?

Em vez de pedir:

> *â€œqual Ã© a classificaÃ§Ã£o correta?â€*

passei a perguntar:

> *â€œessa condiÃ§Ã£o foi atendida?â€*

A norma virou um **fluxo de perguntas**, nÃ£o um texto solto.

Algo como:

- houve impacto ambiental?
- o produto era perigoso?
- o volume ultrapassou determinado limite?

A IA nÃ£o escolhe o caminho.  
Ela apenas responde cada pergunta **uma de cada vez**.

Como um assistente tÃ©cnico lendo o relatÃ³rio em voz alta,  
enquanto a regra decide o prÃ³ximo passo.

---

## O resultado foi quase anticlimÃ¡tico â€” e isso foi Ã³timo

De repente:

- os erros ficaram previsÃ­veis,
- as decisÃµes ficaram explicÃ¡veis,
- e quando algo dava erradoâ€¦ dava para entender *por quÃª*.

A IA deixou de ser um orÃ¡culo misterioso  
e virou um operador extremamente disciplinado.

Ela nÃ£o â€œachaâ€.  
Ela **verifica**.

---

## O que eu aprendi com isso

A maior armadilha ao usar IA em decisÃµes crÃ­ticas Ã© querer que ela seja inteligente demais.

Em ambientes regulados, inteligÃªncia nÃ£o Ã© criatividade.  
Ã‰ **consistÃªncia**.

A IA funciona melhor quando:

- interpreta textos confusos,
- extrai evidÃªncias,
- e respeita limites claros impostos por humanos.

---

## A conclusÃ£o que ficou

Depois de tudo isso, cheguei a uma frase que guia o projeto atÃ© hoje:

> **A IA nÃ£o deve decidir a regra.  
Ela deve ajudar a aplicÃ¡-la.**

Quando fazemos isso, ela deixa de ser um risco â€”  
e passa a ser uma aliada poderosa.

---

ğŸ‘‰ **No prÃ³ximo artigo**, a histÃ³ria fica ainda mais interessante:  
o dia em que percebi que **nem toda ambiguidade Ã© erro da IA** â€”  
Ã s vezes, o mundo Ã© que Ã© ambÃ­g
